{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from operator import itemgetter\n",
    "from typing import List, Dict\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "#LangChain, LangGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "from typing_extensions import List, TypedDict\n",
    "# from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.tools import Tool, tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "\n",
    "\n",
    "# from langchain.tools import DuckDuckGoSearchRun\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_python_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        raise\n",
    "    except IOError as e:\n",
    "        print(f\"Error reading file {file_path}: {str(e)}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error reading file {file_path}: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_imports(code, file_path):\n",
    "    try:\n",
    "            \n",
    "        # Split into lines and find imports\n",
    "        import_lines = []\n",
    "        for line in code.split('\\n'):\n",
    "            line = line.strip()\n",
    "            if line.startswith('import ') or line.startswith('from '):\n",
    "                import_lines.append(line)\n",
    "                \n",
    "        return import_lines\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting imports from file {file_path}: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_pypi(package_name: str) -> str:\n",
    "    \"\"\"Search PyPI for Python package information. Input should be the package name.\n",
    "    Args: \n",
    "        package_name: name of the package \n",
    "    \"\"\"\n",
    "    print(f\"Tool called for package: {package_name}\")\n",
    "    base_url = \"https://pypi.org/pypi\"\n",
    "    try:\n",
    "        try:\n",
    "            response = requests.get(f\"{base_url}/{package_name}/json\")\n",
    "            response.raise_for_status()\n",
    "            info = response.json()\n",
    "        except requests.RequestException as e:\n",
    "            raise Exception(f\"Error fetching PyPI info for {package_name}: {str(e)}\")\n",
    "        result =  json.dumps({\n",
    "            \"name\": info[\"info\"][\"name\"],\n",
    "            \"summary\": info[\"info\"][\"summary\"],\n",
    "        })\n",
    "        print(f\"Tool result: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Could not find package information: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'package_name': {'title': 'Package Name', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(search_pypi.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe Imports Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "# search_packages_tools = [convert_to_openai_tool(search_pypi)]\n",
    "\n",
    "search_packages_tools = [search_pypi]\n",
    "# tools=[\n",
    "#         {\n",
    "#             \"type\": \"function\",\n",
    "#             \"function\": {\n",
    "#                 \"name\": \"search_pypi\",\n",
    "#                 \"description\": \"Search PyPI for Python package information. Input should be the package name.\",\n",
    "#                 \"parameters\": {\n",
    "#                     \"type\": \"object\",\n",
    "#                     \"properties\": {\n",
    "#                         \"package_name\": {\"type\": \"string\", \"description\": \"Package Name\"},\n",
    "                        \n",
    "#                     },\n",
    "#                     \"required\": [\"package_name\"],\n",
    "#                 },\n",
    "#             },\n",
    "#         }\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_imports_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# describe_imports_llm = describe_imports_llm.bind_tools(tools = search_packages_tools, tool_choice=\"required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"You are an expert {code_language} developer.\n",
    "Your will be given code lines that import packages. \n",
    "Your role is to give a brief description of each package\n",
    "\n",
    "You have access to the following tool and you MUST use it:\n",
    "search_pypi: Use this to get information about Python packages from PyPI.\n",
    "\n",
    "For each import:\n",
    "1. Extract the main package name\n",
    "2. Use the search_pypi tool to get package information by calling \"search_pypi(package_name)\"\n",
    "3. Combine the information into a clear description\n",
    "4. If the retuned value of tool is empty use your own knowledge\n",
    "5. If you have no knowledge for this package then it's description should be \"I don't know details about this package\"\n",
    "\n",
    "You must respond in the following JSON format:\n",
    "{{\"Imported_Packages\": [\n",
    "    {{\"name\": \"package1\", \"desc\": \"brief description of package1\"}},\n",
    "    {{\"name\": \"package2\", \"desc\": \"brief description of package2\"}}\n",
    "]}}\n",
    "\n",
    "Rules for the output:\n",
    "1. Use valid JSON format\n",
    "2. Package names should be the exact names from the imports\n",
    "3. Descriptions should be brief and clear\n",
    "4. Do not include any text outside the JSON structure\n",
    "\"\"\"\n",
    "\n",
    "# system_template = \"\"\"You are an expert {code_language} developer.\n",
    "# Your will be given code lines that import packages. \n",
    "# Your role is to give a brief description of each package\n",
    "\n",
    "# You can use the search_pypi tool, but it's optional.\n",
    "# If you know about a package, you can describe it directly.\n",
    "# If you're unsure, you can use search_pypi to get more information.\n",
    "\n",
    "# You must respond in the following JSON format:\n",
    "# {{\"Imported_Packages\": [\n",
    "#     {{\"name\": \"package1\", \"desc\": \"brief description of package1\"}},\n",
    "#     {{\"name\": \"package2\", \"desc\": \"brief description of package2\"}}\n",
    "# ]}}\n",
    "\n",
    "# Rules for the output:\n",
    "# 1. Use valid JSON format\n",
    "# 2. Package names should be the exact names from the imports\n",
    "# 3. Descriptions should be brief and clear\n",
    "# 4. Do not include any text outside the JSON structure\n",
    "# \"\"\"\n",
    "human_template = \"{imports}\"\n",
    "\n",
    "describe_imports_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "describe_imports_chain = (\n",
    "    {\"code_language\": itemgetter(\"code_language\"), \"imports\": itemgetter(\"imports\")}\n",
    "    | describe_imports_prompt | describe_imports_llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "  messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain as a node\n",
    "def call_imports_chain(state):\n",
    "  print(\"Starting chain function\")\n",
    "  last_message= state[\"messages\"][-1]\n",
    "  print(f'last message is \\n {last_message}')\n",
    "  content = json.loads(last_message.content)\n",
    "  print(f'content is {content}')\n",
    "  print(type(content))\n",
    "  chain_input = {\"code_language\": content['code_language'], \n",
    "                 \"imports\": content['imports']}\n",
    "  print(f'chain_input is {chain_input}')\n",
    "  print(type(chain_input))\n",
    "  response = describe_imports_chain.invoke(chain_input)\n",
    "  print(f\"Chain response: {response}\")\n",
    "  return {\"messages\": [AIMessage(content=response)]}\n",
    "#   return {\n",
    "#           \"messages\": [{\n",
    "#               \"role\": \"assistant\",\n",
    "#               \"content\": response\n",
    "#           }]\n",
    "#       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bind model to tool or ToolNode\n",
    "imports_tool_node = ToolNode(search_packages_tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct graph and compile\n",
    "uncompiled_imports_graph = StateGraph(AgentState)\n",
    "uncompiled_imports_graph.add_node(\"imports_agent\", call_imports_chain)\n",
    "uncompiled_imports_graph.add_node(\"imports_action\", imports_tool_node)\n",
    "uncompiled_imports_graph.set_entry_point(\"imports_agent\")\n",
    "def should_continue(state):\n",
    "  last_message = state[\"messages\"][-1]\n",
    "\n",
    "  if last_message.tool_calls:\n",
    "    return \"imports_action\"\n",
    "\n",
    "  return END\n",
    "\n",
    "uncompiled_imports_graph.add_conditional_edges(\n",
    "    \"imports_agent\",\n",
    "    should_continue\n",
    ")\n",
    "\n",
    "uncompiled_imports_graph.add_edge(\"imports_action\", \"imports_agent\")\n",
    "\n",
    "compiled_imports_graph = uncompiled_imports_graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nimport getpass\\nfrom operator import itemgetter\\n\\n\\n#LangChain, LangGraph\\nfrom langchain_openai import ChatOpenAI\\nfrom langgraph.graph import START, StateGraph\\nfrom typing_extensions import List, TypedDict\\nfrom langchain_core.documents import Document\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain.schema.output_parser import StrOutputParser\\n\\ndef read_python_file(file_path):\\n    try:\\n        with open(file_path, \\'r\\', encoding=\\'utf-8\\') as f:\\n            content = f.read()\\n        return content\\n    except FileNotFoundError:\\n        print(f\"File not found: {file_path}\")\\n        raise\\n    except IOError as e:\\n        print(f\"Error reading file {file_path}: {str(e)}\")\\n        raise\\n    except Exception as e:\\n        print(f\"Unexpected error reading file {file_path}: {str(e)}\")\\n        raise'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/home/melghorab/maven_nlp_course/code/Project/Code/test_code.py\"\n",
    "file_content = read_python_file(file_path)\n",
    "file_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['import os',\n",
       " 'import getpass',\n",
       " 'from operator import itemgetter',\n",
       " 'from langchain_openai import ChatOpenAI',\n",
       " 'from langgraph.graph import START, StateGraph',\n",
       " 'from typing_extensions import List, TypedDict',\n",
       " 'from langchain_core.documents import Document',\n",
       " 'from langchain_core.prompts import ChatPromptTemplate',\n",
       " 'from langchain.schema.output_parser import StrOutputParser']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imports = extract_imports(file_content, file_path)\n",
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chain function\n",
      "last message is \n",
      " content='{\"code_language\": \"python\", \"imports\": [\"import os\", \"import getpass\", \"from operator import itemgetter\", \"from langchain_openai import ChatOpenAI\", \"from langgraph.graph import START, StateGraph\", \"from typing_extensions import List, TypedDict\", \"from langchain_core.documents import Document\", \"from langchain_core.prompts import ChatPromptTemplate\", \"from langchain.schema.output_parser import StrOutputParser\"]}' additional_kwargs={} response_metadata={} id='86b01ffc-c0cf-4f76-87d6-81aed0ddb10e'\n",
      "content is {'code_language': 'python', 'imports': ['import os', 'import getpass', 'from operator import itemgetter', 'from langchain_openai import ChatOpenAI', 'from langgraph.graph import START, StateGraph', 'from typing_extensions import List, TypedDict', 'from langchain_core.documents import Document', 'from langchain_core.prompts import ChatPromptTemplate', 'from langchain.schema.output_parser import StrOutputParser']}\n",
      "<class 'dict'>\n",
      "chain_input is {'code_language': 'python', 'imports': ['import os', 'import getpass', 'from operator import itemgetter', 'from langchain_openai import ChatOpenAI', 'from langgraph.graph import START, StateGraph', 'from typing_extensions import List, TypedDict', 'from langchain_core.documents import Document', 'from langchain_core.prompts import ChatPromptTemplate', 'from langchain.schema.output_parser import StrOutputParser']}\n",
      "<class 'dict'>\n",
      "Chain response: {\"Imported_Packages\": [\n",
      "    {\"name\": \"os\", \"desc\": \"A standard library that provides a way of using operating system-dependent functionality like reading or writing to the file system.\"},\n",
      "    {\"name\": \"getpass\", \"desc\": \"A standard library that provides a way to securely handle password prompts without echoing input.\"},\n",
      "    {\"name\": \"operator\", \"desc\": \"A standard library that exports a set of functions corresponding to the intrinsic operators of Python.\"},\n",
      "    {\"name\": \"langchain_openai\", \"desc\": \"A library that provides tools for building applications with OpenAI's language processing capabilities.\"},\n",
      "    {\"name\": \"langgraph\", \"desc\": \"I don't know details about this package\"},\n",
      "    {\"name\": \"typing_extensions\", \"desc\": \"A backport of recent additions to the typing module in Python, providing support for type hints.\"},\n",
      "    {\"name\": \"langchain_core\", \"desc\": \"I don't know details about this package\"},\n",
      "    {\"name\": \"langchain.schema.output_parser\", \"desc\": \"I don't know details about this package\"}\n",
      "]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='{\"code_language\": \"python\", \"imports\": [\"import os\", \"import getpass\", \"from operator import itemgetter\", \"from langchain_openai import ChatOpenAI\", \"from langgraph.graph import START, StateGraph\", \"from typing_extensions import List, TypedDict\", \"from langchain_core.documents import Document\", \"from langchain_core.prompts import ChatPromptTemplate\", \"from langchain.schema.output_parser import StrOutputParser\"]}', additional_kwargs={}, response_metadata={}, id='86b01ffc-c0cf-4f76-87d6-81aed0ddb10e'),\n",
       "  AIMessage(content='{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"desc\": \"A standard library that provides a way of using operating system-dependent functionality like reading or writing to the file system.\"},\\n    {\"name\": \"getpass\", \"desc\": \"A standard library that provides a way to securely handle password prompts without echoing input.\"},\\n    {\"name\": \"operator\", \"desc\": \"A standard library that exports a set of functions corresponding to the intrinsic operators of Python.\"},\\n    {\"name\": \"langchain_openai\", \"desc\": \"A library that provides tools for building applications with OpenAI\\'s language processing capabilities.\"},\\n    {\"name\": \"langgraph\", \"desc\": \"I don\\'t know details about this package\"},\\n    {\"name\": \"typing_extensions\", \"desc\": \"A backport of recent additions to the typing module in Python, providing support for type hints.\"},\\n    {\"name\": \"langchain_core\", \"desc\": \"I don\\'t know details about this package\"},\\n    {\"name\": \"langchain.schema.output_parser\", \"desc\": \"I don\\'t know details about this package\"}\\n]}', additional_kwargs={}, response_metadata={}, id='e554660b-5366-436a-bb4b-5b0bbb1d15ab')]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_message = HumanMessage(content=json.dumps({\n",
    "#     \"code_language\": \"python\",\n",
    "#     \"imports\": imports\n",
    "# }))\n",
    "\n",
    "# result = compiled_imports_graph.invoke({\n",
    "#             \"messages\": [input_message]\n",
    "#         })\n",
    "\n",
    "# result\n",
    "\n",
    "# initial_state = {\n",
    "#     \"messages\": [{\n",
    "#         \"code_language\": \"python\",\n",
    "#         \"imports\": imports\n",
    "#     }]\n",
    "# }\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [{\n",
    "        \"role\": \"human\",\n",
    "        \"content\": json.dumps({\n",
    "            \"code_language\": \"python\",\n",
    "            \"imports\": imports\n",
    "        })\n",
    "    }]\n",
    "}\n",
    "result = compiled_imports_graph.invoke(initial_state)\n",
    "result\n",
    "\n",
    "# inputs = {\"messages\" : [HumanMessage(content={\"code_language\": \"python\", \"imports\": imports})]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chain function\n",
      "last message is \n",
      " content='{\"code_language\": \"python\", \"imports\": [\"import os\", \"import getpass\", \"from operator import itemgetter\", \"from langchain_openai import ChatOpenAI\", \"from langgraph.graph import START, StateGraph\", \"from typing_extensions import List, TypedDict\", \"from langchain_core.documents import Document\", \"from langchain_core.prompts import ChatPromptTemplate\", \"from langchain.schema.output_parser import StrOutputParser\"]}' additional_kwargs={} response_metadata={} id='feeaeda4-a5a5-454f-bd0d-061b7bb9793b'\n",
      "content is {'code_language': 'python', 'imports': ['import os', 'import getpass', 'from operator import itemgetter', 'from langchain_openai import ChatOpenAI', 'from langgraph.graph import START, StateGraph', 'from typing_extensions import List, TypedDict', 'from langchain_core.documents import Document', 'from langchain_core.prompts import ChatPromptTemplate', 'from langchain.schema.output_parser import StrOutputParser']}\n",
      "<class 'dict'>\n",
      "chain_input is {'code_language': 'python', 'imports': ['import os', 'import getpass', 'from operator import itemgetter', 'from langchain_openai import ChatOpenAI', 'from langgraph.graph import START, StateGraph', 'from typing_extensions import List, TypedDict', 'from langchain_core.documents import Document', 'from langchain_core.prompts import ChatPromptTemplate', 'from langchain.schema.output_parser import StrOutputParser']}\n",
      "<class 'dict'>\n",
      "Chain response: \n",
      "Receiving update from node: 'imports_agent'\n",
      "[AIMessage(content='', additional_kwargs={}, response_metadata={}, id='9ce24f21-f1e5-43e5-89bf-4b6e29beeb50')]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async for chunk in compiled_imports_graph.astream(initial_state, stream_mode=\"updates\"):\n",
    "    for node, values in chunk.items():\n",
    "        print(f\"Receiving update from node: '{node}'\")\n",
    "        print(values[\"messages\"])\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response=describe_imports_chain.invoke({\"code_language\": \"python\", \"imports\": imports})\n",
    "response=describe_imports_chain.invoke({'code_language': 'python', 'imports': ['import os', 'import getpass', 'from operator import itemgetter', 'from langchain_openai import ChatOpenAI', 'from langgraph.graph import START, StateGraph']})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_gh46jGv1jZD196HTw3WxnaNZ', 'function': {'arguments': '{\"package_name\":\"requests\"}', 'name': 'search_pypi'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 72, 'total_tokens': 90, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_13eed4fce1', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d8ebc589-e82e-42d4-9c18-c020c81043fa-0', tool_calls=[{'name': 'search_pypi', 'args': {'package_name': 'requests'}, 'id': 'call_gh46jGv1jZD196HTw3WxnaNZ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 72, 'output_tokens': 18, 'total_tokens': 90, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = describe_imports_llm.invoke(\"What tools do you have available?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing tool directly:\n",
      "Tool called for package: pandas\n",
      "Tool result: {\"name\": \"pandas\", \"summary\": \"Powerful data structures for data analysis, time series, and statistics\"}\n",
      "Tool result: {\"name\": \"pandas\", \"summary\": \"Powerful data structures for data analysis, time series, and statistics\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing tool directly:\")\n",
    "result = search_pypi(\"pandas\")\n",
    "print(f\"Tool result: {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f77e94f6ce0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f77e94f7ac0>, root_client=<openai.OpenAI object at 0x7f77e94ec6a0>, root_async_client=<openai.AsyncOpenAI object at 0x7f77e94f4df0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')) kwargs={'tools': [{'type': 'function', 'function': {'name': 'search_pypi', 'description': 'Search PyPI for Python package information. Input should be the package name.\\n    Args: \\n        package_name: name of the package', 'parameters': {'properties': {'package_name': {'type': 'string'}}, 'required': ['package_name'], 'type': 'object'}}}], 'tool_choice': 'required'} config={} config_factories=[]\n"
     ]
    }
   ],
   "source": [
    "print(describe_imports_llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='{\"code_language\": \"python\", \"imports\": [\"import os\", \"import getpass\", \"from operator import itemgetter\", \"from langchain_openai import ChatOpenAI\", \"from langgraph.graph import START, StateGraph\", \"from typing_extensions import List, TypedDict\", \"from langchain_core.documents import Document\", \"from langchain_core.prompts import ChatPromptTemplate\", \"from langchain.schema.output_parser import StrOutputParser\"]}', additional_kwargs={}, response_metadata={}, id='86b01ffc-c0cf-4f76-87d6-81aed0ddb10e'),\n",
       "  AIMessage(content='{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"desc\": \"A standard library that provides a way of using operating system-dependent functionality like reading or writing to the file system.\"},\\n    {\"name\": \"getpass\", \"desc\": \"A standard library that provides a way to securely handle password prompts without echoing input.\"},\\n    {\"name\": \"operator\", \"desc\": \"A standard library that exports a set of functions corresponding to the intrinsic operators of Python.\"},\\n    {\"name\": \"langchain_openai\", \"desc\": \"A library that provides tools for building applications with OpenAI\\'s language processing capabilities.\"},\\n    {\"name\": \"langgraph\", \"desc\": \"I don\\'t know details about this package\"},\\n    {\"name\": \"typing_extensions\", \"desc\": \"A backport of recent additions to the typing module in Python, providing support for type hints.\"},\\n    {\"name\": \"langchain_core\", \"desc\": \"I don\\'t know details about this package\"},\\n    {\"name\": \"langchain.schema.output_parser\", \"desc\": \"I don\\'t know details about this package\"}\\n]}', additional_kwargs={}, response_metadata={}, id='e554660b-5366-436a-bb4b-5b0bbb1d15ab')]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save imports as chunk in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"desc\": \"A standard library that provides a way of using operating system-dependent functionality like reading or writing to the file system.\"},\\n    {\"name\": \"getpass\", \"desc\": \"A standard library that provides a way to securely handle password prompts without echoing input.\"},\\n    {\"name\": \"operator\", \"desc\": \"A standard library that exports a set of functions corresponding to the intrinsic operators of Python.\"},\\n    {\"name\": \"langchain_openai\", \"desc\": \"A library that provides tools for building applications with OpenAI\\'s language processing capabilities.\"},\\n    {\"name\": \"langgraph\", \"desc\": \"I don\\'t know details about this package\"},\\n    {\"name\": \"typing_extensions\", \"desc\": \"A backport of recent additions to the typing module in Python, providing support for type hints.\"},\\n    {\"name\": \"langchain_core\", \"desc\": \"I don\\'t know details about this package\"},\\n    {\"name\": \"langchain.schema.output_parser\", \"desc\": \"I don\\'t know details about this package\"}\\n]}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = result['messages'][-1].content\n",
    "text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35647/4126236278.py:4: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
      "/tmp/ipykernel_35647/4126236278.py:27: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
      "  vectorstore = Qdrant(qdrant_client, collection_name=\"description_rag_data\", embeddings=embedding_model)\n"
     ]
    }
   ],
   "source": [
    "qdrant_client = QdrantClient(\":memory:\")  # Use in-memory or provide host/port\n",
    "\n",
    "# Define embedding model\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Example chunks\n",
    "chunks = [\n",
    "    {\"type\": \"Imported Packages\", \"name\": \"Imported Packages\", \"content\": text},\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=f\"{chunk['type']} - {chunk['name']} - {chunk['content']}\",  # Content for the model\n",
    "        metadata={**chunk}  # Store metadata, but don't put embeddings here\n",
    "    )\n",
    "    for chunk in chunks\n",
    "]\n",
    "embedding_dim = 1536\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=\"description_rag_data\",\n",
    "    vectors_config=VectorParams(size=embedding_dim, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Store in Qdrant with explicit embeddings\n",
    "vectorstore = Qdrant(qdrant_client, collection_name=\"description_rag_data\", embeddings=embedding_model)\n",
    "vectorstore.add_documents(docs)\n",
    "\n",
    "\n",
    "# Define the retriever\n",
    "qdrant_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# # Define the prompt template\n",
    "# rag_prompt = PromptTemplate.from_template(\n",
    "#     \"Given the following retrieved documents:\\n{context}\\nAnswer the question: {question}\"\n",
    "# )\n",
    "\n",
    "# # Define the LLM model (OpenAI ChatGPT)\n",
    "# openai_chat_model = ChatOpenAI(model_name=\"gpt-4\", temperature=0.7)\n",
    "\n",
    "# # Define the RAG chain\n",
    "# rag_chain = (\n",
    "#     {\"context\": itemgetter(\"question\") | qdrant_retriever, \"question\": itemgetter(\"question\")}\n",
    "#     | rag_prompt\n",
    "#     | openai_chat_model\n",
    "#     | StrOutputParser()\n",
    "# )\n",
    "\n",
    "# # Example query\n",
    "# query = {\"question\": \"What are the company policies?\"}\n",
    "# response = rag_chain.invoke(query)\n",
    "\n",
    "# # Print response\n",
    "# print(\"\\nAI Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# embedding_dim = 1536\n",
    "\n",
    "# from langchain_qdrant import QdrantVectorStore\n",
    "# from qdrant_client import QdrantClient\n",
    "# from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "# client = QdrantClient(\":memory:\")\n",
    "\n",
    "# client.create_collection(\n",
    "#     collection_name=\"lcel_doc_v1\",\n",
    "#     vectors_config=VectorParams(size=embedding_dim, distance=Distance.COSINE),\n",
    "# )\n",
    "\n",
    "# vector_store = QdrantVectorStore(\n",
    "#     client=client,\n",
    "#     collection_name=\"lcel_doc_v1\",\n",
    "#     embedding=embedding_model,\n",
    "# )\n",
    "\n",
    "# _ = vector_store.add_texts(texts=chunks)\n",
    "\n",
    "# retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call main LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports_result = result['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "system_template = \"\"\"You are an expert {code_language} developer.\n",
    "Your role is to answer user's questions about code and its description that will be given to you in context\n",
    "\n",
    "Rules for the output:\n",
    "1. Don't answer out of context questions\n",
    "2. Provide a single, clear response using only the given context\n",
    "3. If needed, structure long responses in lists and sections\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"{query}\"\n",
    "main_llm_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template)\n",
    "])\n",
    "\n",
    "# main_chain = (\n",
    "#     {\"code_language\": itemgetter(\"code_language\"),\"context\": itemgetter(\"context\"), \"query\": itemgetter(\"query\")}\n",
    "#     | main_llm_prompt | main_llm | StrOutputParser()\n",
    "# )\n",
    "\n",
    "main_chain = (\n",
    "    {\"context\": itemgetter(\"query\") | qdrant_retriever, \"code_language\": itemgetter(\"code_language\"), \"query\": itemgetter(\"query\"), }\n",
    "    | main_llm_prompt\n",
    "    | main_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"desc\": \"The os module provides a way of using operating system dependent functionality like reading or writing to the file system.\"},\\n    {\"name\": \"getpass\", \"desc\": \"The getpass module provides a secure way to handle password prompts and enables users to input passwords without echoing them to the console.\"},\\n    {\"name\": \"operator\", \"desc\": \"The operator module provides a set of efficient functions corresponding to the intrinsic operators of Python, allowing for functional programming.\"},\\n    {\"name\": \"langchain_openai\", \"desc\": \"LangChain for OpenAI integrates OpenAI models into workflows, enabling building applications that leverage language models.\"},\\n    {\"name\": \"langgraph\", \"desc\": \"No knowledge of this package\"},\\n    {\"name\": \"typing_extensions\", \"desc\": \"The typing_extensions module provides backports of type hints from the standard library\\'s typing module, making them available in earlier Python versions.\"},\\n    {\"name\": \"langchain_core.documents\", \"desc\": \"LangChain Core Documents is part of the LangChain framework, designed to manage and manipulate document data for language models.\"},\\n    {\"name\": \"langchain_core.prompts\", \"desc\": \"LangChain Core Prompts is part of the LangChain framework, providing tools to create and manage prompts for language model inputs.\"},\\n    {\"name\": \"langchain.schema.output_parser\", \"desc\": \"LangChain Schema Output Parser provides functionality for parsing outputs from language models, allowing for better integration and interpretation.\"}\\n]}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = result['messages'][-1].content\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code_language': 'Python', 'query': 'What are the packages used in this code?'}\n",
      "The packages used in the code are:\n",
      "\n",
      "1. **os**: A standard library that provides a way of using operating system-dependent functionality like reading or writing to the file system.\n",
      "2. **getpass**: A standard library that provides a way to securely handle password prompts without echoing input.\n",
      "3. **operator**: A standard library that exports a set of functions corresponding to the intrinsic operators of Python.\n",
      "4. **langchain_openai**: A library that provides tools for building applications with OpenAI's language processing capabilities.\n",
      "5. **langgraph**: Details about this package are not known.\n",
      "6. **typing_extensions**: A backport of recent additions to the typing module in Python, providing support for type hints.\n",
      "7. **langchain_core**: Details about this package are not known.\n",
      "8. **langchain.schema.output_parser**: Details about this package are not known.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The packages used in the code are:\\n\\n1. **os**: A standard library that provides a way of using operating system-dependent functionality like reading or writing to the file system.\\n2. **getpass**: A standard library that provides a way to securely handle password prompts without echoing input.\\n3. **operator**: A standard library that exports a set of functions corresponding to the intrinsic operators of Python.\\n4. **langchain_openai**: A library that provides tools for building applications with OpenAI's language processing capabilities.\\n5. **langgraph**: Details about this package are not known.\\n6. **typing_extensions**: A backport of recent additions to the typing module in Python, providing support for type hints.\\n7. **langchain_core**: Details about this package are not known.\\n8. **langchain.schema.output_parser**: Details about this package are not known.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response=main_chain.invoke({'code_language': 'Python', 'context': context, 'query': 'What are the packages used in this code?'})\n",
    "# response\n",
    "# response=main_chain.invoke({'code_language': 'python', 'context': context, 'query': 'What are the packages used in this code?'})\n",
    "# response\n",
    "\n",
    "# inputs = {\n",
    "#     'code_language': 'Python',\n",
    "#     'context': context,\n",
    "#     'query': 'What are the packages used in this code?'\n",
    "# }\n",
    "\n",
    "inputs = {\n",
    "    'code_language': 'Python',\n",
    "    'query': 'What are the packages used in this code?'\n",
    "}\n",
    "print(inputs)  # Debugging step\n",
    "response = main_chain.invoke(inputs)\n",
    "print(response)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write in Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'type': 'Imported Packages', 'name': 'Imported Packages', 'content': '{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"desc\": \"The os module provides a way of using operating system dependent functionality like reading or writing to the file system.\"},\\n    {\"name\": \"getpass\", \"desc\": \"The getpass module provides a secure way to handle password prompts and enables users to input passwords without echoing them to the console.\"},\\n    {\"name\": \"operator\", \"desc\": \"The operator module provides a set of efficient functions corresponding to the intrinsic operators of Python, allowing for functional programming.\"},\\n    {\"name\": \"langchain_openai\", \"desc\": \"LangChain for OpenAI integrates OpenAI models into workflows, enabling building applications that leverage language models.\"},\\n    {\"name\": \"langgraph\", \"desc\": \"No knowledge of this package\"},\\n    {\"name\": \"typing_extensions\", \"desc\": \"The typing_extensions module provides backports of type hints from the standard library\\'s typing module, making them available in earlier Python versions.\"},\\n    {\"name\": \"langchain_core.documents\", \"desc\": \"LangChain Core Documents is part of the LangChain framework, designed to manage and manipulate document data for language models.\"},\\n    {\"name\": \"langchain_core.prompts\", \"desc\": \"LangChain Core Prompts is part of the LangChain framework, providing tools to create and manage prompts for language model inputs.\"},\\n    {\"name\": \"langchain.schema.output_parser\", \"desc\": \"LangChain Schema Output Parser provides functionality for parsing outputs from language models, allowing for better integration and interpretation.\"}\\n]}'}, page_content='Imported Packages - Imported Packages - {\"Imported_Packages\": [\\n    {\"name\": \"os\", \"desc\": \"The os module provides a way of using operating system dependent functionality like reading or writing to the file system.\"},\\n    {\"name\": \"getpass\", \"desc\": \"The getpass module provides a secure way to handle password prompts and enables users to input passwords without echoing them to the console.\"},\\n    {\"name\": \"operator\", \"desc\": \"The operator module provides a set of efficient functions corresponding to the intrinsic operators of Python, allowing for functional programming.\"},\\n    {\"name\": \"langchain_openai\", \"desc\": \"LangChain for OpenAI integrates OpenAI models into workflows, enabling building applications that leverage language models.\"},\\n    {\"name\": \"langgraph\", \"desc\": \"No knowledge of this package\"},\\n    {\"name\": \"typing_extensions\", \"desc\": \"The typing_extensions module provides backports of type hints from the standard library\\'s typing module, making them available in earlier Python versions.\"},\\n    {\"name\": \"langchain_core.documents\", \"desc\": \"LangChain Core Documents is part of the LangChain framework, designed to manage and manipulate document data for language models.\"},\\n    {\"name\": \"langchain_core.prompts\", \"desc\": \"LangChain Core Prompts is part of the LangChain framework, providing tools to create and manage prompts for language model inputs.\"},\\n    {\"name\": \"langchain.schema.output_parser\", \"desc\": \"LangChain Schema Output Parser provides functionality for parsing outputs from language models, allowing for better integration and interpretation.\"}\\n]}')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_content': 'Imported Packages - Imported Packages - {\"Imported_Packages\": [\\n    {\"name\": \"os\", \"desc\": \"The os module provides a way of using operating system dependent functionality like reading or writing to the file system.\"},\\n    {\"name\": \"getpass\", \"desc\": \"The getpass module provides a secure way to handle password prompts and enables users to input passwords without echoing them to the console.\"},\\n    {\"name\": \"operator\", \"desc\": \"The operator module provides a set of efficient functions corresponding to the intrinsic operators of Python, allowing for functional programming.\"},\\n    {\"name\": \"langchain_openai\", \"desc\": \"LangChain for OpenAI integrates OpenAI models into workflows, enabling building applications that leverage language models.\"},\\n    {\"name\": \"langgraph\", \"desc\": \"No knowledge of this package\"},\\n    {\"name\": \"typing_extensions\", \"desc\": \"The typing_extensions module provides backports of type hints from the standard library\\'s typing module, making them available in earlier Python versions.\"},\\n    {\"name\": \"langchain_core.documents\", \"desc\": \"LangChain Core Documents is part of the LangChain framework, designed to manage and manipulate document data for language models.\"},\\n    {\"name\": \"langchain_core.prompts\", \"desc\": \"LangChain Core Prompts is part of the LangChain framework, providing tools to create and manage prompts for language model inputs.\"},\\n    {\"name\": \"langchain.schema.output_parser\", \"desc\": \"LangChain Schema Output Parser provides functionality for parsing outputs from language models, allowing for better integration and interpretation.\"}\\n]}',\n",
       " 'metadata': {'type': 'Imported Packages',\n",
       "  'name': 'Imported Packages',\n",
       "  'content': '{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"desc\": \"The os module provides a way of using operating system dependent functionality like reading or writing to the file system.\"},\\n    {\"name\": \"getpass\", \"desc\": \"The getpass module provides a secure way to handle password prompts and enables users to input passwords without echoing them to the console.\"},\\n    {\"name\": \"operator\", \"desc\": \"The operator module provides a set of efficient functions corresponding to the intrinsic operators of Python, allowing for functional programming.\"},\\n    {\"name\": \"langchain_openai\", \"desc\": \"LangChain for OpenAI integrates OpenAI models into workflows, enabling building applications that leverage language models.\"},\\n    {\"name\": \"langgraph\", \"desc\": \"No knowledge of this package\"},\\n    {\"name\": \"typing_extensions\", \"desc\": \"The typing_extensions module provides backports of type hints from the standard library\\'s typing module, making them available in earlier Python versions.\"},\\n    {\"name\": \"langchain_core.documents\", \"desc\": \"LangChain Core Documents is part of the LangChain framework, designed to manage and manipulate document data for language models.\"},\\n    {\"name\": \"langchain_core.prompts\", \"desc\": \"LangChain Core Prompts is part of the LangChain framework, providing tools to create and manage prompts for language model inputs.\"},\\n    {\"name\": \"langchain.schema.output_parser\", \"desc\": \"LangChain Schema Output Parser provides functionality for parsing outputs from language models, allowing for better integration and interpretation.\"}\\n]}'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract description chunks from database\n",
    "collection_name = \"description_rag_data\"\n",
    "all_points = qdrant_client.scroll(collection_name=collection_name, limit=1000)[0]  # Adjust limit if needed\n",
    "one_chunk = all_points[0].payload\n",
    "one_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def write_document(\n",
    "    content: Annotated[str, \"Text content to be written into the document.\"],\n",
    "    file_name: Annotated[str, \"File path to save the document.\"],\n",
    ") -> Annotated[str, \"Path of the saved document file.\"]:\n",
    "    \"\"\"Create and save a text document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.write(content)\n",
    "    return f\"Document saved to {file_name}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_content': 'Imported Packages - Imported Packages - {\"Imported_Packages\": [\\n    {\"name\": \"os\", \"desc\": \"The os module provides a way of using operating system dependent functionality like reading or writing to the file system.\"},\\n    {\"name\": \"getpass\", \"desc\": \"The getpass module provides a secure way to handle password prompts and enables users to input passwords without echoing them to the console.\"},\\n    {\"name\": \"operator\", \"desc\": \"The operator module provides a set of efficient functions corresponding to the intrinsic operators of Python, allowing for functional programming.\"},\\n    {\"name\": \"langchain_openai\", \"desc\": \"LangChain for OpenAI integrates OpenAI models into workflows, enabling building applications that leverage language models.\"},\\n    {\"name\": \"langgraph\", \"desc\": \"No knowledge of this package\"},\\n    {\"name\": \"typing_extensions\", \"desc\": \"The typing_extensions module provides backports of type hints from the standard library\\'s typing module, making them available in earlier Python versions.\"},\\n    {\"name\": \"langchain_core.documents\", \"desc\": \"LangChain Core Documents is part of the LangChain framework, designed to manage and manipulate document data for language models.\"},\\n    {\"name\": \"langchain_core.prompts\", \"desc\": \"LangChain Core Prompts is part of the LangChain framework, providing tools to create and manage prompts for language model inputs.\"},\\n    {\"name\": \"langchain.schema.output_parser\", \"desc\": \"LangChain Schema Output Parser provides functionality for parsing outputs from language models, allowing for better integration and interpretation.\"}\\n]}',\n",
       " 'metadata': {'type': 'Imported Packages',\n",
       "  'name': 'Imported Packages',\n",
       "  'content': '{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"desc\": \"The os module provides a way of using operating system dependent functionality like reading or writing to the file system.\"},\\n    {\"name\": \"getpass\", \"desc\": \"The getpass module provides a secure way to handle password prompts and enables users to input passwords without echoing them to the console.\"},\\n    {\"name\": \"operator\", \"desc\": \"The operator module provides a set of efficient functions corresponding to the intrinsic operators of Python, allowing for functional programming.\"},\\n    {\"name\": \"langchain_openai\", \"desc\": \"LangChain for OpenAI integrates OpenAI models into workflows, enabling building applications that leverage language models.\"},\\n    {\"name\": \"langgraph\", \"desc\": \"No knowledge of this package\"},\\n    {\"name\": \"typing_extensions\", \"desc\": \"The typing_extensions module provides backports of type hints from the standard library\\'s typing module, making them available in earlier Python versions.\"},\\n    {\"name\": \"langchain_core.documents\", \"desc\": \"LangChain Core Documents is part of the LangChain framework, designed to manage and manipulate document data for language models.\"},\\n    {\"name\": \"langchain_core.prompts\", \"desc\": \"LangChain Core Prompts is part of the LangChain framework, providing tools to create and manage prompts for language model inputs.\"},\\n    {\"name\": \"langchain.schema.output_parser\", \"desc\": \"LangChain Schema Output Parser provides functionality for parsing outputs from language models, allowing for better integration and interpretation.\"}\\n]}'}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: Imported Packages \n",
      "name: Imported Packages \n",
      "content: {\"Imported_Packages\": [\n",
      "    {\"name\": \"os\", \"desc\": \"The os module provides a way of using operating system dependent functionality like reading or writing to the file system.\"},\n",
      "    {\"name\": \"getpass\", \"desc\": \"The getpass module provides a secure way to handle password prompts and enables users to input passwords without echoing them to the console.\"},\n",
      "    {\"name\": \"operator\", \"desc\": \"The operator module provides a set of efficient functions corresponding to the intrinsic operators of Python, allowing for functional programming.\"},\n",
      "    {\"name\": \"langchain_openai\", \"desc\": \"LangChain for OpenAI integrates OpenAI models into workflows, enabling building applications that leverage language models.\"},\n",
      "    {\"name\": \"langgraph\", \"desc\": \"No knowledge of this package\"},\n",
      "    {\"name\": \"typing_extensions\", \"desc\": \"The typing_extensions module provides backports of type hints from the standard library's typing module, making them available in earlier Python versions.\"},\n",
      "    {\"name\": \"langchain_core.documents\", \"desc\": \"LangChain Core Documents is part of the LangChain framework, designed to manage and manipulate document data for language models.\"},\n",
      "    {\"name\": \"langchain_core.prompts\", \"desc\": \"LangChain Core Prompts is part of the LangChain framework, providing tools to create and manage prompts for language model inputs.\"},\n",
      "    {\"name\": \"langchain.schema.output_parser\", \"desc\": \"LangChain Schema Output Parser provides functionality for parsing outputs from language models, allowing for better integration and interpretation.\"}\n",
      "]}\n"
     ]
    }
   ],
   "source": [
    "input_text = f\"type: {one_chunk['metadata']['type']} \\nname: {one_chunk['metadata']['name']} \\ncontent: {one_chunk['metadata']['content']}\"\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "documenter_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "system_template = \"\"\"You are an expert code documenter.\n",
    "Your role is to write a well structured document that describes code functionality.\n",
    "\n",
    "From the given context:\n",
    "1- type: is the type of the code block (funciton, class, ..)\n",
    "2- name: is the name of the code block\n",
    "3- content: is the description of the code block\n",
    "\n",
    "Instructions:\n",
    "Write a docx document with the following structure Heading 1(type) -> Heading 2(name) -> content\n",
    "\n",
    "Rules for the output:\n",
    "1. Don't write information out of context\n",
    "2. If needed, structure long responses in lists and sections\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"{code_block}\"\n",
    "\n",
    "documenter_llm_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "])\n",
    "\n",
    "documenter_chain = (\n",
    "    {\"context\": itemgetter(\"context\")}\n",
    "    | documenter_llm_prompt\n",
    "    | documenter_llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Imported Packages \n",
      "\n",
      "## Imported Packages \n",
      "\n",
      "The following is a list of imported packages used in the code, detailing their names and descriptions:\n",
      "\n",
      "1. **os**\n",
      "   - The os module provides a way of using operating system dependent functionality like reading or writing to the file system.\n",
      "\n",
      "2. **getpass**\n",
      "   - The getpass module provides a secure way to handle password prompts and enables users to input passwords without echoing them to the console.\n",
      "\n",
      "3. **operator**\n",
      "   - The operator module provides a set of efficient functions corresponding to the intrinsic operators of Python, allowing for functional programming.\n",
      "\n",
      "4. **langchain_openai**\n",
      "   - LangChain for OpenAI integrates OpenAI models into workflows, enabling building applications that leverage language models.\n",
      "\n",
      "5. **langgraph**\n",
      "   - No knowledge of this package.\n",
      "\n",
      "6. **typing_extensions**\n",
      "   - The typing_extensions module provides backports of type hints from the standard library's typing module, making them available in earlier Python versions.\n",
      "\n",
      "7. **langchain_core.documents**\n",
      "   - LangChain Core Documents is part of the LangChain framework, designed to manage and manipulate document data for language models.\n",
      "\n",
      "8. **langchain_core.prompts**\n",
      "   - LangChain Core Prompts is part of the LangChain framework, providing tools to create and manage prompts for language model inputs.\n",
      "\n",
      "9. **langchain.schema.output_parser**\n",
      "   - LangChain Schema Output Parser provides functionality for parsing outputs from language models, allowing for better integration and interpretation.\n"
     ]
    }
   ],
   "source": [
    "document_response = documenter_chain.invoke({\"context\": input_text})\n",
    "print(document_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import re\n",
    "\n",
    "# @tool\n",
    "def write_to_docx(documentation_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Writes the AI-generated documentation to a .docx file and returns the file path.\n",
    "    \"\"\"\n",
    "    doc = Document()\n",
    "    # doc.add_heading(\"Code Documentation\", level=1)\n",
    "\n",
    "    lines = documentation_text.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        if line.startswith(\"# \"):  # Section Heading\n",
    "            doc.add_heading(line[2:], level=1)\n",
    "        elif line.startswith(\"## \"):  # Subsection Heading\n",
    "            doc.add_heading(line[3:], level=2)\n",
    "        else:  # Normal paragraph\n",
    "            doc.add_paragraph(line)\n",
    "            # paragraph = doc.add_paragraph(line)\n",
    "            # parts = re.split(r\"(\\*\\*(.*?)\\*\\*)\", line)  # Split by **bold text**\n",
    "            # print(parts)\n",
    "            # for part in parts:\n",
    "            #     if part.startswith(\"**\") and part.endswith(\"**\"):\n",
    "            #         paragraph.add_run(part[2:-2]).bold = True  # Remove ** before adding bold text\n",
    "            #     elif part:  # Normal text\n",
    "            #         paragraph.add_run(part)\n",
    "\n",
    "    # Save document\n",
    "    file_path = \"generated_documentation.docx\"\n",
    "    doc.save(file_path)\n",
    "    return file_path  # Return file path for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'write_to_docx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mwrite_to_docx\u001b[49m(document_response)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'write_to_docx' is not defined"
     ]
    }
   ],
   "source": [
    "file = write_to_docx(document_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate using RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'type': 'Imported Packages', 'name': 'Imported Packages', 'content': '{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"desc\": \"A standard library that provides a way of using operating system-dependent functionality like reading or writing to the file system.\"},\\n    {\"name\": \"getpass\", \"desc\": \"A standard library that provides a way to securely handle password prompts without echoing input.\"},\\n    {\"name\": \"operator\", \"desc\": \"A standard library that exports a set of functions corresponding to the intrinsic operators of Python.\"},\\n    {\"name\": \"langchain_openai\", \"desc\": \"A library that provides tools for building applications with OpenAI\\'s language processing capabilities.\"},\\n    {\"name\": \"langgraph\", \"desc\": \"I don\\'t know details about this package\"},\\n    {\"name\": \"typing_extensions\", \"desc\": \"A backport of recent additions to the typing module in Python, providing support for type hints.\"},\\n    {\"name\": \"langchain_core\", \"desc\": \"I don\\'t know details about this package\"},\\n    {\"name\": \"langchain.schema.output_parser\", \"desc\": \"I don\\'t know details about this package\"}\\n]}'}, page_content='Imported Packages - Imported Packages - {\"Imported_Packages\": [\\n    {\"name\": \"os\", \"desc\": \"A standard library that provides a way of using operating system-dependent functionality like reading or writing to the file system.\"},\\n    {\"name\": \"getpass\", \"desc\": \"A standard library that provides a way to securely handle password prompts without echoing input.\"},\\n    {\"name\": \"operator\", \"desc\": \"A standard library that exports a set of functions corresponding to the intrinsic operators of Python.\"},\\n    {\"name\": \"langchain_openai\", \"desc\": \"A library that provides tools for building applications with OpenAI\\'s language processing capabilities.\"},\\n    {\"name\": \"langgraph\", \"desc\": \"I don\\'t know details about this package\"},\\n    {\"name\": \"typing_extensions\", \"desc\": \"A backport of recent additions to the typing module in Python, providing support for type hints.\"},\\n    {\"name\": \"langchain_core\", \"desc\": \"I don\\'t know details about this package\"},\\n    {\"name\": \"langchain.schema.output_parser\", \"desc\": \"I don\\'t know details about this package\"}\\n]}')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Imported Packages - Imported Packages'}, page_content='{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"desc\": \"A standard library that provides a way of using operating system-dependent functionality like reading or writing to the file system.\"},\\n    {\"name\": \"getpass\", \"desc\": \"A standard library that provides a way to securely handle password prompts without echoing input.\"},\\n    {\"name\": \"operator\", \"desc\": \"A standard library that exports a set of functions corresponding to the intrinsic operators of Python.\"},\\n    {\"name\": \"langchain_openai\", \"desc\": \"A library that provides tools for building applications with OpenAI\\'s language processing capabilities.\"},\\n    {\"name\": \"langgraph\", \"desc\": \"I don\\'t know details about this package\"},\\n    {\"name\": \"typing_extensions\", \"desc\": \"A backport of recent additions to the typing module in Python, providing support for type hints.\"},\\n    {\"name\": \"langchain_core\", \"desc\": \"I don\\'t know details about this package\"},\\n    {\"name\": \"langchain.schema.output_parser\", \"desc\": \"I don\\'t know details about this package\"}\\n]}')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_docs = [\n",
    "    Document(\n",
    "        page_content=doc.metadata['content'],  # Extract actual content\n",
    "        metadata={\"source\": f\"{doc.metadata['type']} - {doc.metadata['name']}\"}  # Define a unique source\n",
    "    )\n",
    "    for doc in docs\n",
    "]\n",
    "ragas_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating personas: 100%|| 1/1 [00:01<00:00,  1.39s/it]                                         \n",
      "Generating Scenarios: 100%|| 1/1 [00:01<00:00,  1.33s/it]\n",
      "Generating Samples: 100%|| 10/10 [04:29<00:00, 26.97s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you explain the role of langchain_core in ...</td>\n",
       "      <td>[{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...</td>\n",
       "      <td>The context does not provide specific details ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the os package in Python and how does ...</td>\n",
       "      <td>[{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...</td>\n",
       "      <td>The os package is a standard library in Python...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What typing_extensions do in Python?</td>\n",
       "      <td>[{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...</td>\n",
       "      <td>typing_extensions is a backport of recent addi...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can you elaborate on the functionalities provi...</td>\n",
       "      <td>[{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...</td>\n",
       "      <td>The 'os' package is a standard library in Pyth...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the purpose of the langgraph package i...</td>\n",
       "      <td>[{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...</td>\n",
       "      <td>The context does not provide specific details ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the purpose of the langgraph package i...</td>\n",
       "      <td>[{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...</td>\n",
       "      <td>The context does not provide specific details ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the role of langchain_core in Python d...</td>\n",
       "      <td>[{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...</td>\n",
       "      <td>The context does not provide specific details ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What langchain.schema.output_parser do?</td>\n",
       "      <td>[{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...</td>\n",
       "      <td>I don't know details about this package.</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What the os package do in Python and how it he...</td>\n",
       "      <td>[{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...</td>\n",
       "      <td>The os package is a standard library that prov...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Can you tell me what langchain_core is used fo...</td>\n",
       "      <td>[{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...</td>\n",
       "      <td>I don't know details about the langchain_core ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Can you explain the role of langchain_core in ...   \n",
       "1  What is the os package in Python and how does ...   \n",
       "2               What typing_extensions do in Python?   \n",
       "3  Can you elaborate on the functionalities provi...   \n",
       "4  What is the purpose of the langgraph package i...   \n",
       "5  What is the purpose of the langgraph package i...   \n",
       "6  What is the role of langchain_core in Python d...   \n",
       "7            What langchain.schema.output_parser do?   \n",
       "8  What the os package do in Python and how it he...   \n",
       "9  Can you tell me what langchain_core is used fo...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...   \n",
       "1  [{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...   \n",
       "2  [{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...   \n",
       "3  [{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...   \n",
       "4  [{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...   \n",
       "5  [{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...   \n",
       "6  [{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...   \n",
       "7  [{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...   \n",
       "8  [{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...   \n",
       "9  [{\"Imported_Packages\": [\\n    {\"name\": \"os\", \"...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  The context does not provide specific details ...   \n",
       "1  The os package is a standard library in Python...   \n",
       "2  typing_extensions is a backport of recent addi...   \n",
       "3  The 'os' package is a standard library in Pyth...   \n",
       "4  The context does not provide specific details ...   \n",
       "5  The context does not provide specific details ...   \n",
       "6  The context does not provide specific details ...   \n",
       "7           I don't know details about this package.   \n",
       "8  The os package is a standard library that prov...   \n",
       "9  I don't know details about the langchain_core ...   \n",
       "\n",
       "                       synthesizer_name  \n",
       "0  single_hop_specifc_query_synthesizer  \n",
       "1  single_hop_specifc_query_synthesizer  \n",
       "2  single_hop_specifc_query_synthesizer  \n",
       "3  single_hop_specifc_query_synthesizer  \n",
       "4  single_hop_specifc_query_synthesizer  \n",
       "5  single_hop_specifc_query_synthesizer  \n",
       "6  single_hop_specifc_query_synthesizer  \n",
       "7  single_hop_specifc_query_synthesizer  \n",
       "8  single_hop_specifc_query_synthesizer  \n",
       "9  single_hop_specifc_query_synthesizer  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate test questions \n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(ragas_docs, testset_size=10)\n",
    "dataset.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "documenter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
